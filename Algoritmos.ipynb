{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caracterização e visualização de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures,OneHotEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "from category_encoders.one_hot import OrdinalEncoder\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDataframe = pd.read_csv(\"test_categorical_variables.csv\")\n",
    "\n",
    "#y = newDataframe['SalePrice']\n",
    "y = pd.DataFrame(newDataframe['SalePrice'])\n",
    "X = newDataframe.drop(['SalePrice'], axis=1)\n",
    "\n",
    "y[[\"SalePrice\"]] = y[[\"SalePrice\"]].apply(np.log)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold\n",
    "\n",
    "def validacao_cruzada2(modelo):\n",
    "  \n",
    "  kf = KFold(n_splits=10, shuffle=True, random_state=3)\n",
    "  scores = cross_validate(modelo, X_train, y_train, cv=kf, scoring =('r2', 'neg_mean_squared_error'), return_train_score=True)\n",
    "  return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_rmse(y_real, y_pred): \n",
    "    return mean_squared_error(y_real, y_pred)**0.5\n",
    "\n",
    "def avalia_classificador(clf, kf, X, y, f_metrica):\n",
    "    metrica_valid = []\n",
    "    metrica_train = []\n",
    "    r2_valid = []\n",
    "    r2_train = []\n",
    "    \n",
    "    y_preds = np.zeros(X.shape[0])\n",
    "    \n",
    "    for train, valid in kf.split(X,y):\n",
    "        x_train = X.iloc[train] \n",
    "        y_train = y.iloc[train]\n",
    "        x_valid = X.iloc[valid] \n",
    "        y_valid = y.iloc[valid]\n",
    "        clf.fit(x_train, y_train) \n",
    "        y_pred_train = clf.predict(x_train)\n",
    "        y_pred_valid = clf.predict(x_valid)\n",
    "        y_preds[valid] = y_pred_valid[0] \n",
    "        \n",
    "        metrica_valid.append(f_metrica(y_valid, y_pred_valid)) \n",
    "        metrica_train.append(f_metrica(y_train, y_pred_train))\n",
    "        r2_valid.append(r2_score(y_valid, y_pred_valid))\n",
    "        r2_train.append(r2_score(y_train, y_pred_train))\n",
    "          \n",
    "    # retorna as previsões e a média das métricas de treino e validação\n",
    "    # obtidas nas iterações do Kfold\n",
    "    return y_preds, np.array(metrica_valid).mean(), np.array(metrica_train).mean(), np.array(r2_valid).mean(), np.array(r2_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " REGRESSOR LINEAR:\n",
      " \n",
      " Métrica  DENTRO da amostra  FORA da amostra\n",
      " -------  -----------------  ---------------\n",
      "     mse             0.0001           0.0001\n",
      "    rmse             0.0082           0.0109\n",
      "      r2             0.9376           0.8980\n",
      " Validação cruzada\n",
      " Métrica  DENTRO da amostra  FORA da amostra\n",
      " -------  -----------------  ---------------\n",
      "    rmse             0.0083           0.0123\n",
      "      r2             0.9371           0.8500\n",
      "['fit_time', 'score_time', 'test_neg_mean_squared_error', 'test_r2', 'train_neg_mean_squared_error', 'train_r2']\n",
      "[0.89503472 0.89884523 0.41682026 0.73852389 0.88673919 0.93061628\n",
      " 0.73386645 0.86199354 0.89352611 0.91408331]\n",
      "0.817004898121417\n",
      "[0.93883629 0.93764915 0.94053019 0.94541864 0.93873627 0.93506722\n",
      " 0.94608051 0.94164028 0.93992036 0.93673868]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "regressor_linear = LinearRegression(fit_intercept = True)\n",
    "\n",
    "regressor_linear = regressor_linear.fit(X_train, y_train)\n",
    "\n",
    "y_resposta_treino = regressor_linear.predict(X_train)\n",
    "y_resposta_teste  = regressor_linear.predict(X_test)\n",
    "\n",
    "print(' ')\n",
    "print(' REGRESSOR LINEAR:')\n",
    "print(' ')\n",
    "\n",
    "print(' Métrica  DENTRO da amostra  FORA da amostra')\n",
    "print(' -------  -----------------  ---------------')\n",
    "\n",
    "mse_in  = mean_squared_error(y_train,y_resposta_treino)\n",
    "rmse_in = math.sqrt(mse_in)\n",
    "r2_in   = r2_score(y_train,y_resposta_treino)\n",
    "\n",
    "mse_out  = mean_squared_error(y_test,y_resposta_teste)\n",
    "rmse_out = math.sqrt(mse_out)\n",
    "r2_out   = r2_score(y_test,y_resposta_teste)\n",
    "\n",
    "print(' %7s  %17.4f  %15.4f' % (  'mse' ,  mse_in ,  mse_out ) )\n",
    "print(' %7s  %17.4f  %15.4f' % ( 'rmse' , rmse_in , rmse_out ) )\n",
    "print(' %7s  %17.4f  %15.4f' % (   'r2' ,   r2_in ,   r2_out ) )\n",
    "\n",
    "kf = KFold(n_splits=9, shuffle=True, random_state=7)\n",
    "\n",
    "preds, rmse_val, rmse_train, r2test, r2train = avalia_classificador(regressor_linear, kf, X, y, f_rmse)\n",
    "\n",
    "print(' ')\n",
    "print(' VALIDAÇÃO CRUZADA:')\n",
    "print(' ')\n",
    "\n",
    "print(' Métrica  DENTRO da amostra  FORA da amostra')\n",
    "print(' -------  -----------------  ---------------')\n",
    "\n",
    "print(' %7s  %17.4f  %15.4f' % ( 'rmse' , rmse_train , rmse_val ) )\n",
    "print(' %7s  %17.4f  %15.4f' % (   'r2' ,   r2train ,   r2test ) )\n",
    "\n",
    "sco = validacao_cruzada2(regressor_linear)\n",
    "print(sorted(sco.keys()))\n",
    "\n",
    "import statistics\n",
    "mean = statistics.mean(sco['test_r2'])\n",
    "print(sco['test_r2'])\n",
    "print(mean)\n",
    "print(sco['train_r2'])\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, pred_test_tree)))\n",
    "#print(sco['train_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuições, correlações, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descrição do procedimento de validação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Não se aplica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " REGRESSÃO BAYESIANA:\n",
      " \n",
      " Métrica  DENTRO da amostra  FORA da amostra\n",
      " -------  -----------------  ---------------\n",
      "     mse             0.0001           0.0001\n",
      "    rmse             0.0099           0.0111\n",
      "      r2             0.9080           0.8954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression\n",
    "\n",
    "\n",
    "bayesian_ridge = BayesianRidge(compute_score=True)\n",
    "\n",
    "bayesian_ridge = bayesian_ridge.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_resposta_treino = bayesian_ridge.predict(X_train)\n",
    "y_resposta_teste  = bayesian_ridge.predict(X_test)\n",
    "\n",
    "print(' ')\n",
    "print(' REGRESSÃO BAYESIANA:')\n",
    "print(' ')\n",
    "\n",
    "print(' Métrica  DENTRO da amostra  FORA da amostra')\n",
    "print(' -------  -----------------  ---------------')\n",
    "\n",
    "mse_in  = mean_squared_error(y_train,y_resposta_treino)\n",
    "rmse_in = math.sqrt(mse_in)\n",
    "r2_in   = r2_score(y_train,y_resposta_treino)\n",
    "\n",
    "mse_out  = mean_squared_error(y_test,y_resposta_teste)\n",
    "rmse_out = math.sqrt(mse_out)\n",
    "r2_out   = r2_score(y_test,y_resposta_teste)\n",
    "\n",
    "print(' %7s  %17.4f  %15.4f' % (  'mse' ,  mse_in ,  mse_out ) )\n",
    "print(' %7s  %17.4f  %15.4f' % ( 'rmse' , rmse_in , rmse_out ) )\n",
    "print(' %7s  %17.4f  %15.4f' % (   'r2' ,   r2_in ,   r2_out ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árvores de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " ARVORE DE DECISÃO:\n",
      " \n",
      " Métrica  DENTRO da amostra  FORA da amostra\n",
      " -------  -----------------  ---------------\n",
      "     mse             0.0000           0.0003\n",
      "    rmse             0.0000           0.0174\n",
      "      r2             1.0000           0.7423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "#from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn import metrics\n",
    "#import math\n",
    "\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeRegressor()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_resposta_treino = clf.predict(X_train)\n",
    "y_resposta_teste = clf.predict(X_test)\n",
    "\n",
    "print(' ')\n",
    "print(' ARVORE DE DECISÃO:')\n",
    "print(' ')\n",
    "\n",
    "print(' Métrica  DENTRO da amostra  FORA da amostra')\n",
    "print(' -------  -----------------  ---------------')\n",
    "\n",
    "mse_in  = mean_squared_error(y_train,y_resposta_treino)\n",
    "rmse_in = math.sqrt(mse_in)\n",
    "r2_in   = r2_score(y_train,y_resposta_treino)\n",
    "\n",
    "mse_out  = mean_squared_error(y_test,y_resposta_teste)\n",
    "rmse_out = math.sqrt(mse_out)\n",
    "r2_out   = r2_score(y_test,y_resposta_teste)\n",
    "\n",
    "print(' %7s  %17.4f  %15.4f' % (  'mse' ,  mse_in ,  mse_out ) )\n",
    "print(' %7s  %17.4f  %15.4f' % ( 'rmse' , rmse_in , rmse_out ) )\n",
    "print(' %7s  %17.4f  %15.4f' % (   'r2' ,   r2_in ,   r2_out ) )\n",
    "#print(\"Acurácia:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " RANDOM FOREST:\n",
      " \n",
      " Métrica  DENTRO da amostra  FORA da amostra\n",
      " -------  -----------------  ---------------\n",
      "     mse             0.0000           0.0001\n",
      "    rmse             0.0048           0.0117\n",
      "      r2             0.9789           0.8824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "#import math\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = RandomForestRegressor()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train.values.ravel())\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_resposta_treino = clf.predict(X_train)\n",
    "y_resposta_teste = clf.predict(X_test)\n",
    "\n",
    "print(' ')\n",
    "print(' RANDOM FOREST:')\n",
    "print(' ')\n",
    "\n",
    "print(' Métrica  DENTRO da amostra  FORA da amostra')\n",
    "print(' -------  -----------------  ---------------')\n",
    "\n",
    "mse_in  = mean_squared_error(y_train,y_resposta_treino)\n",
    "rmse_in = math.sqrt(mse_in)\n",
    "r2_in   = r2_score(y_train,y_resposta_treino)\n",
    "\n",
    "mse_out  = mean_squared_error(y_test,y_resposta_teste)\n",
    "rmse_out = math.sqrt(mse_out)\n",
    "r2_out   = r2_score(y_test,y_resposta_teste)\n",
    "\n",
    "print(' %7s  %17.4f  %15.4f' % (  'mse' ,  mse_in ,  mse_out ) )\n",
    "print(' %7s  %17.4f  %15.4f' % ( 'rmse' , rmse_in , rmse_out ) )\n",
    "print(' %7s  %17.4f  %15.4f' % (   'r2' ,   r2_in ,   r2_out ) )\n",
    "#print(\"Acurácia:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " GRADIENT BOOSTING:\n",
      " \n",
      " Métrica  DENTRO da amostra  FORA da amostra\n",
      " -------  -----------------  ---------------\n",
      "     mse             0.0000           0.0001\n",
      "    rmse             0.0061           0.0107\n",
      "      r2             0.9652           0.9020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.ensemble import GradientBoostingClassifier\\nfrom sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\\nfrom numpy import mean,std\\n\\nmodel = GradientBoostingClassifier()\\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\\nn_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\\nprint('Acurácia: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import metrics\n",
    "#import math\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train.values.ravel())\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_resposta_treino = clf.predict(X_train)\n",
    "y_resposta_teste = clf.predict(X_test)\n",
    "\n",
    "print(' ')\n",
    "print(' GRADIENT BOOSTING:')\n",
    "print(' ')\n",
    "\n",
    "print(' Métrica  DENTRO da amostra  FORA da amostra')\n",
    "print(' -------  -----------------  ---------------')\n",
    "\n",
    "mse_in  = mean_squared_error(y_train,y_resposta_treino)\n",
    "rmse_in = math.sqrt(mse_in)\n",
    "r2_in   = r2_score(y_train,y_resposta_treino)\n",
    "\n",
    "mse_out  = mean_squared_error(y_test,y_resposta_teste)\n",
    "rmse_out = math.sqrt(mse_out)\n",
    "r2_out   = r2_score(y_test,y_resposta_teste)\n",
    "\n",
    "print(' %7s  %17.4f  %15.4f' % (  'mse' ,  mse_in ,  mse_out ) )\n",
    "print(' %7s  %17.4f  %15.4f' % ( 'rmse' , rmse_in , rmse_out ) )\n",
    "print(' %7s  %17.4f  %15.4f' % (   'r2' ,   r2_in ,   r2_out ) )\n",
    "#print(\"Acurácia:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\"\"\"\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from numpy import mean,std\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Acurácia: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " SUPPORT VECTOR MACHINES RBF KERNEL:\n",
      " \n",
      " Métrica  DENTRO da amostra  FORA da amostra\n",
      " -------  -----------------  ---------------\n",
      "     mse             0.0012           0.0013\n",
      "    rmse             0.0342           0.0356\n",
      "      r2            -0.0889          -0.0804\n",
      " \n",
      " SUPPORT VECTOR MACHINES LINEAR KERNEL:\n",
      " \n",
      " Métrica  DENTRO da amostra  FORA da amostra\n",
      " -------  -----------------  ---------------\n",
      "     mse             0.0011           0.0012\n",
      "    rmse             0.0335           0.0340\n",
      "      r2            -0.0455           0.0132\n",
      " \n",
      " SUPPORT VECTOR MACHINES POLYNOMIAL KERNEL:\n",
      " \n",
      " Métrica  DENTRO da amostra  FORA da amostra\n",
      " -------  -----------------  ---------------\n",
      "     mse             0.0014           0.0014\n",
      "    rmse             0.0378           0.0380\n",
      "      r2            -0.3344          -0.2315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn import metrics\n",
    "#import math\n",
    "\n",
    "# Fit regression model\n",
    "svr_rbf = SVR(kernel=\"rbf\", C=100, gamma=0.1, epsilon=0.1)\n",
    "svr_lin = SVR(kernel=\"linear\", C=100, gamma=\"auto\")\n",
    "svr_poly = SVR(kernel=\"poly\", C=100, gamma=\"auto\", degree=3, epsilon=0.1, coef0=1)\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "#clf = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "svr_rbf = svr_rbf.fit(X_train,y_train.values.ravel())\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_resposta_treino = svr_rbf.predict(X_train)\n",
    "y_resposta_teste = svr_rbf.predict(X_test)\n",
    "\n",
    "print(' ')\n",
    "print(' SUPPORT VECTOR MACHINES RBF KERNEL:')\n",
    "print(' ')\n",
    "\n",
    "print(' Métrica  DENTRO da amostra  FORA da amostra')\n",
    "print(' -------  -----------------  ---------------')\n",
    "\n",
    "mse_in  = mean_squared_error(y_train,y_resposta_treino)\n",
    "rmse_in = math.sqrt(mse_in)\n",
    "r2_in   = r2_score(y_train,y_resposta_treino)\n",
    "\n",
    "mse_out  = mean_squared_error(y_test,y_resposta_teste)\n",
    "rmse_out = math.sqrt(mse_out)\n",
    "r2_out   = r2_score(y_test,y_resposta_teste)\n",
    "\n",
    "print(' %7s  %17.4f  %15.4f' % (  'mse' ,  mse_in ,  mse_out ) )\n",
    "print(' %7s  %17.4f  %15.4f' % ( 'rmse' , rmse_in , rmse_out ) )\n",
    "print(' %7s  %17.4f  %15.4f' % (   'r2' ,   r2_in ,   r2_out ) )\n",
    "\n",
    "#******************************************************************\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "svr_lin = svr_lin.fit(X_train,y_train.values.ravel())\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_resposta_treino = svr_lin.predict(X_train)\n",
    "y_resposta_teste = svr_lin.predict(X_test)\n",
    "\n",
    "print(' ')\n",
    "print(' SUPPORT VECTOR MACHINES LINEAR KERNEL:')\n",
    "print(' ')\n",
    "\n",
    "print(' Métrica  DENTRO da amostra  FORA da amostra')\n",
    "print(' -------  -----------------  ---------------')\n",
    "\n",
    "mse_in  = mean_squared_error(y_train,y_resposta_treino)\n",
    "rmse_in = math.sqrt(mse_in)\n",
    "r2_in   = r2_score(y_train,y_resposta_treino)\n",
    "\n",
    "mse_out  = mean_squared_error(y_test,y_resposta_teste)\n",
    "rmse_out = math.sqrt(mse_out)\n",
    "r2_out   = r2_score(y_test,y_resposta_teste)\n",
    "\n",
    "print(' %7s  %17.4f  %15.4f' % (  'mse' ,  mse_in ,  mse_out ) )\n",
    "print(' %7s  %17.4f  %15.4f' % ( 'rmse' , rmse_in , rmse_out ) )\n",
    "print(' %7s  %17.4f  %15.4f' % (   'r2' ,   r2_in ,   r2_out ) )\n",
    "\n",
    "#***************************************************************\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "svr_poly = svr_poly.fit(X_train,y_train.values.ravel())\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_resposta_treino = svr_poly.predict(X_train)\n",
    "y_resposta_teste = svr_poly.predict(X_test)\n",
    "\n",
    "print(' ')\n",
    "print(' SUPPORT VECTOR MACHINES POLYNOMIAL KERNEL:')\n",
    "print(' ')\n",
    "\n",
    "print(' Métrica  DENTRO da amostra  FORA da amostra')\n",
    "print(' -------  -----------------  ---------------')\n",
    "\n",
    "mse_in  = mean_squared_error(y_train,y_resposta_treino)\n",
    "rmse_in = math.sqrt(mse_in)\n",
    "r2_in   = r2_score(y_train,y_resposta_treino)\n",
    "\n",
    "mse_out  = mean_squared_error(y_test,y_resposta_teste)\n",
    "rmse_out = math.sqrt(mse_out)\n",
    "r2_out   = r2_score(y_test,y_resposta_teste)\n",
    "\n",
    "print(' %7s  %17.4f  %15.4f' % (  'mse' ,  mse_in ,  mse_out ) )\n",
    "print(' %7s  %17.4f  %15.4f' % ( 'rmse' , rmse_in , rmse_out ) )\n",
    "print(' %7s  %17.4f  %15.4f' % (   'r2' ,   r2_in ,   r2_out ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes Neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This MLPRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4868/1585510258.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mscore1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidacao_cruzada\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#Predict the response for test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0my_resposta_treino\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0my_resposta_teste\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1405\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \"\"\"\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This MLPRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "\n",
    "def validacao_cruzada(modelo):\n",
    "  \n",
    "  kf = KFold(n_splits=10)\n",
    "  scores = cross_validate(modelo, X_train, y_train, cv=kf, scoring='r2', return_train_score=True)\n",
    "  return scores\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "#regr = MLPRegressor(random_state=64, max_iter=50000).fit(X_train, y_train.values.ravel())\n",
    "\n",
    "regr = MLPRegressor(random_state=1234, solver='adam', activation='relu')\n",
    "\n",
    "score1 = validacao_cruzada(regr)\n",
    "#Predict the response for test dataset\n",
    "y_resposta_treino = regr.predict(X_train)\n",
    "y_resposta_teste = regr.predict(X_test)\n",
    "\n",
    "print(' ')\n",
    "print(' NEURAL NETWORK:')\n",
    "print(' ')\n",
    "\n",
    "print(' Métrica  DENTRO da amostra  FORA da amostra')\n",
    "print(' -------  -----------------  ---------------')\n",
    "\n",
    "mse_in  = mean_squared_error(y_train,y_resposta_treino)\n",
    "rmse_in = math.sqrt(mse_in)\n",
    "r2_in   = r2_score(y_train,y_resposta_treino)\n",
    "\n",
    "mse_out  = mean_squared_error(y_test,y_resposta_teste)\n",
    "rmse_out = math.sqrt(mse_out)\n",
    "r2_out   = r2_score(y_test,y_resposta_teste)\n",
    "\n",
    "print(' %7s  %17.4f  %15.4f' % (  'mse' ,  mse_in ,  mse_out ) )\n",
    "print(' %7s  %17.4f  %15.4f' % ( 'rmse' , rmse_in , rmse_out ) )\n",
    "print(' %7s  %17.4f  %15.4f' % (   'r2' ,   r2_in ,   r2_out ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redes Neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
